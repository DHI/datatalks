---
title: Data Talk - Large Language Models
author: Jesper Mariegaard and Clemens Cremer
date: 2023-02-07
date-format: long
slide-number: c/t
transition: slide
format: revealjs
auto-stretch: false # do not resize figures to fit the slide
jupyter: python3
width: 1920
height: 1080
execute: 
  freeze: auto
  enable: true
---


# **Poll**: have you used an AI assistant before? 



# AI assistants - you probably use them every day

:::: columns
::: {.column width=50%}
- **Typing** on your smartphone (autocomplete)
- **Search** accuracy and relevance (google, bing,...)
- Language **translation** (deepL, google translate,...)
- Chatbots for **customer service** and support
- **Content creation** (e.g. marketing material, product descriptions, blog posts,...)
- **Data analysis** (extract insights from large amounts of text data) 
- **Coding**...
:::
::: {.column width=50%}
![](figures/autocomplete.png){width=100%}
:::
::::



# AI Assistants: Foundations 

- **Process natural language** 
- currently **large language models (LLM)** 
- A type of **generative AI** model 
- Examples: GPT-3, BERT, T5, LaMDA, GPT-Neo, GPT-Codex
- Are **conversational** (keeping track of state) 
- Can be **very expensive to train**
- Working memory is limited 10-40k characters (you can't write a book with it in a go )


::: footer
https://www.youtube.com/watch?v=lnA9DMvHtfI
:::


## A **very brief** history of natural language models

- are not new but **originated 1950s - 1960s** 
- got a **boost with introduction of deep learning** in 1990s and particularly
- **unsupervised learning** (no labels for unstructured data)

``` {python}	
import matplotlib.pyplot as plt
import numpy as np
import matplotlib
matplotlib.rcParams.update({'font.size': 22})

#models = ['**ELIZA (1966)**\nELIZA was one of the earliest NLP models developed by Joseph Weizenbaum. It was designed as a mock Rogerian psychotherapist and could carry on simple conversations with users.', 'SHRDLU (1970)\nSHRDLU was a language model developed by Terry Winograd that could understand and respond to natural language commands in a block-world simulation.', 'PARRY (1972)\nPARRY was a conversational AI model developed by Kenneth Colby, designed to simulate a paranoid patient in a mental hospital.', 'R1 (1980s)\nR1 was a rule-based NLP system developed by researcher Steven Pinker, that could understand and generate simple sentences.', 'CYC (1984)\nCYC was an early attempt at creating a "general Knowledge Base" of common-sense knowledge.', 'ALICE (1995)\nALICE was an AI model that could hold conversations and respond to user input in natural language. It was developed by Richard Wallace and was one of the first NLP models to be used widely on the Internet.', 'Siri (2011)\nSiri was a virtual assistant developed by Apple Inc., that used natural language processing and generation to carry out tasks and respond to user requests.', 'Google Assistant (2016)\nGoogle Assistant is a virtual assistant developed by Google that uses NLP to answer questions, perform tasks, and control other devices.', 'ELMo (2018) - ELMo was one of the first deep learning-based NLP models that could be fine-tuned for specific tasks.','OpenAI GPT (2018)\nOpenAI GPT was a transformer-based language model that used a large-scale pre-training technique to generate text, answer questions, and perform other language-related tasks.']


# Define the data to be plotted
models = ['ELIZA (MIT)', 'SHRDLU (MIT)', 'PARRY (Stanford)', 'R1 (Carnegie Mellon)', 'CYC (Cycorp)', 'ALICE (ALICE Foundation)', 'Siri (SRI and Apple)', 'Google Assistant (Google)', 'OpenAI GPT (OpenAI)', 'GitHub Copilot (Github and Microsoft)', 'ChatGPT (OpenAI)']
years = [1966, 1970, 1972, 1980, 1984, 1995, 2011, 2016, 2018, 2021, 2022]

# Create the plot
fig, ax = plt.subplots(figsize=(22,5))
ax.spines['left'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)

# Remove y-ticks
plt.yticks([])

# Add labels to the x-axis
for i, model in enumerate(models):
    ax.annotate(model, (years[i], 0), xytext=(0,5), textcoords='offset points', ha='center', va='bottom', rotation=90)

# Add time arrow
ax.annotate('', xy=(2023, 0), xycoords='data', xytext=(1960, 0),
            textcoords='data', arrowprops=dict(arrowstyle="->",
                                                connectionstyle="arc3"))

# Add gridlines and limit the x-axis
ax.grid(axis='x')
ax.set_xlim(1960, 2023)

# Add labels and title
ax.set_xlabel('Year')
ax.set_title('Timeline of Natural Language Processing Models')

# Show the plot
plt.show()


```


## more recent years 

:::: columns
::: {.column width=40%}
- **GPT**-like (Generative Pretrained Transformer) GPT-3.x or GPT-Neo, Dall-E (e.g. chatGPT, chatBCG) by **OpenAI**, >175 Billion parameters (GPT-4 expected to be >100x)
- **BERT** (Bidirectional Encoder Representations from Transformers) by **Google**, ~340 Million parameters
- **BART/T5**-like (Bidirectional Encoder Representations from Transformers, T5: Text-to-Text Transfer Transformer) by **Facebook**, ~400 Million parameters
- **LaMDA** (Language Model for Dialogue Applications) **Google** >135 bn parameters
- **PaLM** (Pretrained Autoregressive Language Model) **Google** > 540 bn parameters

**why are parameters important?**
- parameters related to sophistication of the model incl. handling tasks not being trained for (GPT2 could not do language translation while GPT3 can)
:::
::: {.column width=60%}
![](figures/model_parameters.png)
:::
::::

::: footer
Links and sources: [1](https://www.omegavp.com/articles/introduction-to-large-language-models/), [2](https://huggingface.co/course/chapter1/4?fw=pt), [3](https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html)
:::


# Assistants for code

- **generation** (e.g. code snippets, documentation, ...)
	- Explain code
	- Writing documentation

- **refactoring** (e.g. make code more readable, more efficient,...)
	- Improved existing code
	- Rewrite code using correct style (refactor code made by non-native Python devs)
	- Rewrite code using ideomatic constructs (make code Pythonic)
	- Simplify code
	- Exploring alternatives

- **testing and debugging** (e.g. find bugs, find security vulnerabilities,...)


## ChatGPT

![](figures/chatGPT1.png){.fragment .fade-left .absolute left=30 height="1000"}

![](figures/chatGPT2.png){.fragment .fade-left .absolute right=30 height="1000"}

![](figures/chatGPT3.png){.fragment .fade-left .absolute left=30 height="1000"}

![](figures/chatGPT4.png){.fragment .fade-left .absolute right=30 height="1000"}

![](figures/chatGPT5.png){.fragment .fade-left .absolute left=30 height="1000"}	

![](figures/chatGPT6.png){.fragment .fade-left .absolute right=30 height="1000"}

![](figures/chatGPT7.png){.fragment .fade-left .absolute left=30 height="1000"}
	
![](figures/chatGPT8.png){.fragment .fade-left .absolute right=30 height="1000"}
	
![](figures/chatGPT9.png){.fragment .fade-left .absolute left=30 height="1000"}	



# Github copilot (GPT-Codex)

- Codex: GPT3 fine tuned for programming tasks 
- translating natural language to code
- trained on GitHub codebase
- more context aware in your environment
- <font color=red> shortcuts (distinguish between namespace and copilot autocomplete)
- look in copilot vs plugin description for bits to use </font>
- https://copilot.github.com/
- https://copilot.github.com/blog/introducing-copilot



# Where is it going?
- Wild west
- many things still unclear
- pros and cons as with every new technology



## Should we have **legal and ethical concerns**? 
 no, it can sort those out itself

![](figures/bar_exam.png){width=70%}

::: {.fragment}
...with a B to C grade though
:::

::: footer
[source](https://www.reuters.com/legal/transactional/chatgpt-passes-law-school-exams-despite-mediocre-performance-2023-01-25/)
:::

## Ok, probably we should consider some **open questions**

### Copyright  
**Art**: “If you train the AI to make Picasso-like works, or Mondrian-like works, and it makes one that is sufficiently similar, that could be a copyright infringement claim,” Mark Lemley, director of Stanford Law School’s Program in Law, Science and Technology

![](figures/dalle_picasso.png){height=70%, origin=center}

::: footer
[source](https://news.bloomberglaw.com/ip-law/wild-west-of-generative-ai-raises-novel-copyright-questions)
:::

## Open questions

### Copyright
**Music**: “If you train the AI to make music that sounds like a particular artist, and it makes a song that is sufficiently similar, that could be a copyright infringement claim,” Mark Lemley, director of Stanford Law School’s Program in Law, Science and Technology

::: footer
<font color="red"> this quote came from Copilot and cannot be found on the internet
</font>
:::

## Open questions

### Copyright
**Code and Open Source**: „Those duplications fail to include author attribution and licensing details, key elements of most open source software agreements, the plaintiffs said.“ from ongoing lawsuit against Copilot and OpenAI

![](figures/code.png){width=50%}

::: footer
[source](https://news.bloomberglaw.com/ip-law/wild-west-of-generative-ai-raises-novel-copyright-questions)
:::

## Open questions

### Security and privacy
ChatGPT is already used to build hacking tools at scale 

![](figures/hacking.png)

::: footer
[source](https://www.hackread.com/hackers-openai-chatgpt-malware/), [image](https://interestingengineering.com/culture/russian-hackers-chatgpt-malicious-code)
:::


## Open questions

### Ethical aspects and code of conduct

**Sophisticated bullshit and misinformation on steroids**

"Stack Overflow, the Q&A site for programmers, has banned ChatGPT-generated answers because **even its low-quality answers can be plausible-sounding.**" 

![](figures/guardian_misinformation.png){width="50%"}


::: footer
[source](https://www.zdnet.com/article/openai-is-hiring-developers-to-make-chatgpt-better-at-coding/)
:::

## Open questions
### Ethical aspects and code of conduct

**Hippocratic Oath**: Do no harm, respect privacy of patients

![](figures/doctor.png){width="30%"}


::: footer
[source](https://stanford-cs324.github.io/winter2022/lectures/legality/)
:::


# Ways forward

- should it be banned or restricted from education and elsewhere?
- can we cite or acknowledge sources „Written in Cooperation with AI?“
- identify bullshit (from CV)


## positive perspectives by critical people 
- "I learned also learned writing by looking at other peoples work and getting inspired." Corey Doctorow     

- “Everybody loved Napster, but we all kind of knew it was illegal,” Butterick said. The digital **music streaming industry** that emerged later **did a better job at bringing artists and creators into the conversation, he added, and the AI industry should follow that model.**“ Butterick (filed a copilot lawsuit)

- "The bigger **potential for the profession here is that a lawyer could use ChatGPT to produce a rough first draft and just make their practice that much more effective**" Jonathan Choi (Prof. at Minnesota Law School, Evaluating ChatGPT performance on Bar exam)

::: footer
[source](https://podcasts.voxmedia.com/show/pivot), [source 2](https://www.reuters.com/legal/transactional/chatgpt-passes-law-school-exams-despite-mediocre-performance-2023-01-25/)
:::


# Am I useless now and what can I do?

	- "(Yann) LeCun (META Chief AI Scientist and Touring Award Winner) recently 
		- likened coding assistants such as Copilot to cruise control in cars. 
		- "Your hands need to remain on the wheel at all times," 
		- because **Copilot can generate errors in code with no awareness of the error**." [2](https://www.zdnet.com/article/openai-is-hiring-developers-to-make-chatgpt-better-at-coding/)
 


## potential (longer term)
- prohibitive cost (and environmental impact) to train LLM from scratch
- limited variety in LLMs will exist
- paid services in the works (e.g. ChatGPT Plus 20$/mo and ChatGPT API) [[1]](https://openai.com/blog/chatgpt-plus/)

- Chat GPT started a focused efford to improve code [[2]](https://www.zdnet.com/article/openai-is-hiring-developers-to-make-chatgpt-better-at-coding/)
- learning from other sources (images, audio recodings, videos, etc.)


- domain knowledge infused LLMs (build on pretrained LLMs)
- even this predictions might be false (e.g. transformer killer)

::: footer
[further reading](https://hai.stanford.edu/news/how-large-language-models-will-transform-science-society-and-ai)
:::

## what does it mean for me? (short term)

- <font color=red> example CV </font>
- you are using Assistants anyway. But if you haven't tried ChatGPT and Copilot --> try! It is free 
- adapt to leverage higher productivity  
- options apart from ChatGPT and copilot (YouChat, Jasper, and Chatsonic)

- prompt crafting: learn to ask the right questions or questions right

- if everyone can use it, everyone can do it --> basic programming skills no longer required?
- new skillsets needed?
	- new workflows and ways of working --> adopt workflows including LLMs 
	- unlearning old habits
	- critical mindset more important than ever --> bullshit does scale now
	- abitlity to review is important
- discussion...  
	- how do you see this being used in your day to day work? 


## For DHI engineers... 

- Text
    - Background information (be careful)  
    - Proposal and Report writing (insert application for job image here)
		- Differ in tone of voice,...
    - Presentations (slides)
		- try quarto
		- try chatBCG
- Code
    - Documentation    
    - Tests