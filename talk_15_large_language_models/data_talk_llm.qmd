---
title: Data Talk - Large Language Models
author: Jesper Mariegaard and Clemens Cremer
date: 2023-02-07
date-format: long
slide-number: c/t
transition: slide
format: revealjs
width: 1920
height: 1080
jupyter: python3
execute: 
  freeze: auto
  enable: true
---



# agenda

- general introduction LLM  
- history from Johan
- examples chatgpt (record some in case it doesn't work)  
    - quick insight into some area (CAREFUL)  
	- reformatting table  
	- explain code
- example copilot  
	- quick functions
    - plotting and formatting (e.g. annotations) 

- where is this going   
- what does it mean for us?   



# general introduction LLM

- large language models (LLM)
- A type of generative AI model 
- Examples: GPT-3, BERT, T5, LaMDA, GPT-Neo, Dall-E, GPT-Codex
- process and generate natural language (e.g. text)
- also capable of text to image or other formats
- keeping track of state (conversational)
- working memory is limited 10-40k characters (you can't write a book with it in a go )


::: footer
https://www.youtube.com/watch?v=lnA9DMvHtfI
:::


## history
- are not new but originated 1950s - 1960s (e.g. ELIZA 1966 at MIT)
- got a boost with introduction of deep learning in 1990s and particularly
- unsupervised learning (no labels for unstructured data)


## examples for applications

- typing on your smartphone (autocomplete)
- search accuracy and relevance (google, bing,...)
- language translation (deepL, google translate,...)
- chatbots for customer service and support
- content creation (e.g. marketing material, product descriptions, blog posts,...)
- data analysis (extract insights from large amounts of text data)




## broad overview 

:::: columns
::: {.column width=50%}
- **GPT**-like (Generative Pretrained Transformer) GPT-3.x or GPT-Neo, Dall-E (e.g. chatGPT, chatBCG) by **OpenAI**, >175 Billion parameters (GPT-4 expected to be >100x)
- **BERT** (Bidirectional Encoder Representations from Transformers) by **Google**, ~340 Million parameters
- **BART/T5**-like (Bidirectional Encoder Representations from Transformers, T5: Text-to-Text Transfer Transformer) by **Facebook**, ~400 Million parameters
- LaMDA (Language Model for Dialogue Applications) **Google** >135 bn parameters

**why are parameters important?**
- parameters related to sophistication of the model incl. handling tasks not being trained for (GPT2 could not do language translation while GPT3 can)
:::
::: {.column width=50%}
![Briefest history of transformers](figures/transformers_chrono_huggingface.svg)
![Parameters](figures/model_parameters.png)
:::
::::

::: footer
Links and sources: [1](https://www.omegavp.com/articles/introduction-to-large-language-models/), [2](https://huggingface.co/course/chapter1/4?fw=pt), [3](https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html)
:::



# notes on using ChatGPT for code

- Explain code
- Improved existing code
- Rewrite code using correct style (refactor code made by non-native Python devs)
- Rewrite code using ideomatic constructs (make code Pythonic)
- Simplify code
- Exploring alternatives
- Writing documentation
- Writing tests
- Tracking down bugs



# github copilot (GPT-Codex)

- Codex: GPT3 fine tuned for programming tasks 
- translating natural language to code
- trained on GitHub codebase
- more context aware in your environment
- https://copilot.github.com/
- https://copilot.github.com/blog/introducing-copilot


# where is it going 
- many things still unclear
- some good some bad sides to it


## criticism
- sophisticated bullshit and misinformation on steroids
	- "Stack Overflow, the Q&A site for programmers, has banned ChatGPT-generated answers because even its low-quality answers can be plausible-sounding." [1](https://www.zdnet.com/article/openai-is-hiring-developers-to-make-chatgpt-better-at-coding/)
	- "(Yann) LeCun (META Chief AI Scientist and Touring Award Winner) recently likened coding assistants such as Copilot to cruise control in cars. "Your hands need to remain on the wheel at all times," because Copilot can generate errors in code with no awareness of the error." [2](https://www.zdnet.com/article/openai-is-hiring-developers-to-make-chatgpt-better-at-coding/)
- security and privacy
	- ChatGPT to build hacking tools [3](https://www.hackread.com/hackers-openai-chatgpt-malware/)  
- intellectual property  
	- some not very accurate tools to identify AI-generated content exist [4](https://www.zdnet.com/article/what-is-chatgpt-and-why-does-it-matter-heres-everything-you-need-to-know/)
	- citations could be handled with "written in cooperation with chatGPT"  



## potential (longer term)
- prohibitive cost (and environmental impact) to train LLM from scratch
- limited variety in LLMs will exist
- paid services in the works (e.g. ChatGPT Plus 20$/mo and ChatGPT API) [[1]](https://openai.com/blog/chatgpt-plus/)

- Chat GPT started a focused efford to improve code [[2]](https://www.zdnet.com/article/openai-is-hiring-developers-to-make-chatgpt-better-at-coding/)
- learning from other sources (images, audio recodings, videos, etc.)

- domain knowledge infused LLMs
- even this predictions might be false (e.g. transformer killer)

::: footer
[further reading](https://hai.stanford.edu/news/how-large-language-models-will-transform-science-society-and-ai)
:::

## what does it mean for me? (short term)

- if you haven't tried --> try! It is free 
- adapt to leverage higher productivity  
- options apart from ChatGPT and copilot (YouChat, Jasper, and Chatsonic)

- prompt crafting: learn to ask the right questions or questions right

- if everyone can use it, everyone can do it --> basic programming skills no longer required?
- new skillsets needed?
	- new workflows and ways of working --> adopt workflows including LLMs 
	- unlearning old habits
	- critical mindset more important than ever --> bullshit does scale now
	- abitlity to review is important
- discussion...  


## For DHI engineers... 

- Text
    - Background information (be careful)  
    - Proposal and Report writing (insert application for job image here)
		- Differ in tone of voice,...
    - Presentations (slides)
		- try quarto
		- try chatBCG
- Code
    - Documentation    
    - Tests