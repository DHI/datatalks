{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Unsupervised Learning with scikit-learn'\n",
        "author: 'Henrik Andersson'\n",
        "date: 2024-05-30\n",
        "format: \n",
        "    revealjs:\n",
        "       embed-resources: true\n",
        "\n",
        "slide-number: true\n",
        "echo: true\n",
        "code-annotations: hover\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Machine Learning\n",
        "\n",
        "   ![](images/ml_map.svg)\n",
        "\n",
        "## Unsupervised Learning Overview\n",
        "*Find patterns in data without explicit labels*\n",
        "\n",
        "* Dimensionality Reduction\n",
        "* Clustering\n",
        "* Anomaly Detection\n",
        "\n",
        "\n",
        "##  Scikit-learn Unsupervised API\n",
        "\n",
        "`X` : Data matrix (n_samples, n_features)\n",
        "\n",
        "::: {.incremental}\n",
        "* `fit(X)`: Learn from the data\n",
        "* `transform(X)`: Apply the transformation\n",
        "* `fit_transform(X)`: Learn and apply in one step\n",
        "* `inverse_transform(X)`: Reverse the transformation\n",
        "* `predict(X)`: Predict labels or values\n",
        "* `fit_predict(X)`: Learn and predict in one step\n",
        ":::\n",
        "\n",
        "## Introduction to Dimensionality Reduction\n",
        "\n",
        "*Reducing the number of features (columns) while keeping most of the information*\n",
        "\n",
        ". . .\n",
        "\n",
        "`X` (n_samples, n_features) $\\rightarrow$  `X'`  (n_samples, n_components)\n",
        "\n",
        "## Principal Component Analysis (PCA)\n",
        "* A linear transformation\n",
        "* Finds the directions of maximum variance in the data\n",
        "* Very fast and efficient\n",
        "\n",
        "## PCA Example with scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "X = np.random.multivariate_normal(mean=[0, 0], cov=[[1, 0.9], [0.9, 1]], size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
        "ax[0].scatter(X[:, 0], X[:, 1], label='Original Data')\n",
        "ax[0].scatter(X_pca[:, 0], X_pca[:, 1], label='Transformed Data')\n",
        "ax[0].set_xlabel('Feature 1')\n",
        "ax[0].set_ylabel('Feature 2')\n",
        "ax[0].legend()\n",
        "\n",
        "ovar = np.var(X, axis=0)\n",
        "pvar = np.var(X_pca, axis=0)\n",
        "\n",
        "# make a bar chart with the variance of each feature in the original and transformed data\n",
        "ax[1].bar(['Feature 1', 'Feature 2'], ovar, label='Original Data')\n",
        "ax[1].bar(['PC1', 'PC2'], pvar, label='Transformed Data')\n",
        "ax[1].set_ylabel('Variance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PCA Wine data {.smaller}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import load_wine\n",
        "X= load_wine(as_frame=True)['data']\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(X.corr(), cmap='coolwarm', vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "Xsc = StandardScaler().fit_transform(X)\n",
        "pca = PCA()\n",
        "pca.fit(Xsc);\n",
        "\n",
        "plt.bar(range(1, pca.n_components_+1), pca.explained_variance_)\n",
        "plt.ylabel('Explained variance')\n",
        "plt.xlabel('Principal component');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig,ax = plt.subplots()\n",
        "\n",
        "ax.bar(range(1, 14), loadings[:,0])\n",
        "ax.set_ylim(-1,1)\n",
        "ax.set_xticks(range(1,14))\n",
        "ax.set_xticklabels(X.columns,rotation=90)\n",
        "ax.set_ylabel('Loadings for PC1');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipelines {.smaller}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "pipe = make_pipeline(StandardScaler(),\n",
        "                     PCA(n_components=2),\n",
        "                     KMeans(n_clusters=3))\n",
        "\n",
        "pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.notes}\n",
        "* ML workflows consist of multiple steps\n",
        "* Scikit-learn pipelines simplify the process\n",
        "* Ensures consistent preprocessing and modeling in training and testing\n",
        ":::\n",
        "\n",
        "## PCA with MIKE data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mikeio\n",
        "da = mikeio.read(\"data/ns_hs.dfsu\")[0]\n",
        "da.isel(time=-1).plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "da.values[np.isnan(da.values)] = 0\n",
        "\n",
        "pipe = make_pipeline(\n",
        "                     StandardScaler(),\n",
        "                     PCA(n_components=50))\n",
        "\n",
        "Xtr = pipe.fit_transform(da.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "n_components = pipe.named_steps['pca'].n_components_\n",
        "plt.bar(range(1,n_components+1), pipe.named_steps['pca'].explained_variance_)\n",
        "plt.yscale('log')\n",
        "plt.ylabel('Explained variance')\n",
        "plt.xlabel('Principal component');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Xrec = pipe.inverse_transform(Xtr)\n",
        "darec = mikeio.DataArray(Xrec,\n",
        "                         time=da.time, \n",
        "                         item=da.item,\n",
        "                         geometry=da.geometry)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: false\n",
        "fig, ax = plt.subplots(ncols=2)\n",
        "\n",
        "da.isel(time=-1).plot(ax=ax[0], title=\"Original\", add_colorbar=False, vmin=0,vmax=0.9);\n",
        "# remove axis labels and ticks to make a clean plot\n",
        "ax[0].set_xlabel('')\n",
        "ax[0].set_ylabel('')\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "darec.isel(time=-1).plot(ax=ax[1], title=\"Reconstructed\", add_colorbar=False, vmin=0,vmax=0.9);\n",
        "ax[1].set_xlabel('')\n",
        "ax[1].set_ylabel('')\n",
        "ax[1].set_xticks([])\n",
        "ax[1].set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rel_err = (da - darec)*100 / da\n",
        "rel_err "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: false\n",
        "timestep = -1\n",
        "ax = (rel_err.isel(time=timestep)\n",
        "                             .plot(title=\"Relative reconstruction error (%)\",\n",
        "                                  cmap='coolwarm', vmin=-2, vmax=2,\n",
        "                                  label=\"\", levels=9));\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PCA with MIKE data - Loadings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: false\n",
        "\n",
        "loadings = pipe.named_steps['pca'].components_.T * np.sqrt(pipe.named_steps['pca'].explained_variance_)\n",
        "\n",
        "n_components = 6\n",
        "\n",
        "fig, ax = plt.subplots(ncols=6, figsize=(15,4))\n",
        "\n",
        "for i in range(n_components):\n",
        "    daloading = mikeio.DataArray(loadings[:,i], geometry=da.geometry)\n",
        "    daloading.plot(ax=ax[i], title=f\"PC{i+1}\", add_colorbar=False, vmin=-1, vmax=1,cmap='coolwarm')\n",
        "    ax[i].set_xticks([])\n",
        "    ax[i].set_yticks([])\n",
        "    ax[i].set_xlabel('')\n",
        "    ax[i].set_ylabel('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## T-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
        "\n",
        "::: {.incremental}\n",
        "* Non-linear dimensionality reduction\n",
        "* Preserves local structure in the data\n",
        "* Useful for visualization\n",
        "* Does **not** support inverse transformation\n",
        ":::\n",
        "\n",
        "## Digits data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "X, y= load_digits(return_X_y=True)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "# visualize the first 10 digits\n",
        "fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    axes[i].imshow(X[i].reshape(8, 8), cmap='gray')\n",
        "    axes[i].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, init='pca')\n",
        "X_ts = tsne.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "plt.scatter(X_ts[:, 0], X_ts[:, 1], c=y, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Clustering\n",
        "\n",
        "*Grouping similar data points together*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "pred = kmeans.fit_predict(X)\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50, c=pred, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Means Clustering\n",
        "\n",
        "*Identify **K** clusters in the data*\n",
        ". . .\n",
        "\n",
        "1. Initialize cluster centroids randomly\n",
        "2. Assign each data point to the nearest centroid\n",
        "3. Update the centroids based on the mean of the assigned data points\n",
        "4. Repeat steps 2 and 3 until convergence\n",
        "\n",
        ". . .\n",
        "\n",
        "*Remember to scale the data before applying K-Means*\n",
        "\n",
        "## K-Means example wine data {.smaller}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "data_dict = load_wine(as_frame=True)\n",
        "X = data_dict['data']\n",
        "y = data_dict['target']\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.express as px\n",
        "\n",
        "px.scatter_3d(X, x='flavanoids', y='color_intensity', z='alcohol')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pipe = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    TSNE(n_components=2, init='pca')\n",
        "    )\n",
        "\n",
        "Xtr = pipe.fit_transform(X)\n",
        "\n",
        "plt.scatter(Xtr[:, 0], Xtr[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "labels = kmeans.fit_predict(X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "plt.scatter(Xtr[:, 0], Xtr[:, 1], c=labels, cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.crosstab(y, labels, rownames=['True'], colnames=['Cluster'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Anomaly Detection\n",
        "\n",
        "*Identify outliers in the data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=300, centers=2, cluster_std=0.20, random_state=0)\n",
        "X[0] = [1.5, 2.0]\n",
        "X[1] = [2.5, 3.2]\n",
        "X[2] = [0.5, 1.0]\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "model = IsolationForest(contamination=0.01)\n",
        "y_pred = model.fit_predict(X)\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50, c=y_pred, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Star Wars characters data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(\"data/starwars.csv\").dropna(subset=['mass', 'height'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "px.scatter(df, x='height', y='mass', hover_name='name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Isolation Forest\n",
        "\n",
        "* Based on decision trees\n",
        "* Randomly select features, splits data\n",
        "* Anomalies are isolated in few splits\n",
        "* Combines results from multiple trees (forest)\n",
        "\n",
        "## Isolation Forest example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "X = df[['height', 'mass']]\n",
        "\n",
        "clf = IsolationForest(contamination=0.01)\n",
        "\n",
        "y_pred = clf.fit_predict(X)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "df['anomaly'] = y_pred\n",
        "px.scatter(df, x='height', y='mass', color='anomaly', hover_name='name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "df[df['anomaly']==-1][['name', 'height', 'mass', 'anomaly']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "\n",
        "::: {.incremental}\n",
        "* `scikit-learn` provides a wide range of unsupervised learning algorithms\n",
        "* **Dimensionality reduction** : Extract important features from data, efficiency, compression and visualization\n",
        "* **Clustering** : Group similar data points together, semi-supervised learning\n",
        "* **Anomaly detection** : Identify outliers in data\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}